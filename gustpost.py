import streamlit as st
import requests
from bs4 import BeautifulSoup
import time
import random
import re
import json
import pandas as pd
import sqlite3
from urllib.parse import urljoin, urlparse
from datetime import datetime
from dataclasses import dataclass, asdict
from typing import List, Dict, Optional
import plotly.express as px
import plotly.graph_objects as go
from concurrent.futures import ThreadPoolExecutor, as_completed
import asyncio
import aiohttp
from io import BytesIO
from collections import Counter, defaultdict
import warnings
warnings.filterwarnings('ignore')

# NLTK setup
try:
    import nltk
    nltk.download('punkt', quiet=True)
    nltk.download('stopwords', quiet=True)
    from textblob import TextBlob
    from textstat import flesch_reading_ease
except ImportError:
    pass

# Page config
st.set_page_config(
    page_title="ðŸš€ ULTRA ULTIMATE Guest Posting Finder",
    page_icon="ðŸŽ¯",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS
st.markdown("""
<style>
.main-header { background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); padding: 2rem; border-radius: 15px; color: white; text-align: center; margin-bottom: 2rem; box-shadow: 0 10px 30px rgba(0,0,0,0.3); }
.metric-card { background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); padding: 1.5rem; border-radius: 12px; color: white; text-align: center; margin: 0.5rem 0; box-shadow: 0 5px 15px rgba(0,0,0,0.2); }
.site-card { background: white; padding: 1.5rem; border-radius: 12px; margin: 1rem 0; box-shadow: 0 5px 20px rgba(0,0,0,0.1); border-left: 5px solid #4CAF50; }
.platinum-site { border-left-color: #9C27B0 !important; }
.gold-site { border-left-color: #FF9800 !important; }
.silver-site { border-left-color: #607D8B !important; }
.bronze-site { border-left-color: #795548 !important; }
.low-site { border-left-color: #f44336 !important; }
.success-badge { background: #4CAF50; color: white; padding: 4px 12px; border-radius: 20px; font-size: 12px; font-weight: bold; margin: 2px; display: inline-block; }
.action-button { background: linear-gradient(45deg, #667eea, #764ba2); color: white; border: none; padding: 8px 16px; border-radius: 6px; cursor: pointer; font-size: 12px; margin: 2px; }
.guest-post-url { background: #e8f5e8; padding: 8px; border-radius: 5px; margin: 5px 0; border-left: 3px solid #4CAF50; }
</style>
""", unsafe_allow_html=True)

@dataclass
class UltimateGuestPostSite:
    domain: str = ""
    url: str = ""
    title: str = ""
    description: str = ""
    emails: List[str] = None
    contact_forms: List[str] = None
    phone_numbers: List[str] = None
    social_media: Dict[str, str] = None
    estimated_da: int = 0
    estimated_pa: int = 0
    estimated_traffic: int = 0
    content_quality_score: int = 0
    readability_score: float = 0.0
    confidence_score: int = 0
    confidence_level: str = "low"
    overall_score: float = 0.0
    priority_level: str = "Low"
    success_probability: float = 0.0
    do_follow_links: bool = False
    submission_requirements: List[str] = None
    preferred_topics: List[str] = None
    guest_post_url: str = ""  # NEW: Specific guest post page URL
    guest_post_confidence: int = 0  # NEW: Confidence level for guest post page
    found_guidelines: bool = False  # NEW: If submission guidelines found

class UltraUltimateConfig:
    STEALTH_USER_AGENTS = [
        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.1 Safari/605.1.15',
        'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/119.0'
    ]
    
    # Guest post specific URL patterns to look for
    GUEST_POST_URL_PATTERNS = [
        'write-for-us', 'guest-post', 'guest-blog', 'contribute',
        'submit-article', 'write-for-me', 'guest-author', 'become-a-contributor',
        'submission-guidelines', 'guest-posting', 'guest-contribution',
        'article-submission', 'blog-guidelines', 'contribute-to-our-blog'
    ]
    
    # Content patterns indicating guest posting
    GUEST_POST_CONTENT_PATTERNS = [
        'write for us', 'guest post', 'guest article', 'submit your article',
        'contribute to our', 'guest blogging', 'submission guidelines',
        'become a contributor', 'guest author guidelines', 'want to write for',
        'looking for writers', 'accepting guest posts', 'guest post guidelines'
    ]

class UltraUltimateGuestPostingFinder:
    def __init__(self):
        self.config = UltraUltimateConfig()
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': random.choice(self.config.STEALTH_USER_AGENTS),
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8'
        })
        self.conn = sqlite3.connect(':memory:')
        self.cursor = self.conn.cursor()
        self.cursor.execute('''CREATE TABLE sites (id INTEGER PRIMARY KEY, data TEXT)''')
        self.conn.commit()
        self.results: List[UltimateGuestPostSite] = []

    def generate_queries(self, niche: str) -> List[str]:
        patterns = [
            f'"{niche}" "write for us"',
            f'"{niche}" "guest post"', 
            f'"{niche}" "guest post guidelines"',
            f'"{niche}" "submit article"',
            f'"{niche}" "become a contributor"',
            f'"{niche}" site:blog "write for us"',
            f'"{niche}" inurl:write-for-us',
            f'"{niche}" inurl:guest-post',
            f'"{niche}" "accepting guest posts"',
            f'"{niche}" "contribute to our blog"'
        ]
        return patterns

    async def scrape_duckduckgo(self, query: str, max_results: int) -> List[str]:
        urls = []
        params = {'q': query, 'format': 'json', 'no_html': '1'}
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get('https://api.duckduckgo.com/', params=params) as resp:
                    if resp.status != 200:
                        return urls
                    text = await resp.text()
                    
                    try:
                        data = json.loads(text)
                    except json.JSONDecodeError:
                        if text.startswith('callback(') and text.endswith(');'):
                            json_str = text[9:-2]
                            data = json.loads(json_str)
                        else:
                            return urls
                    
                    if 'Results' in data:
                        for result in data['Results'][:max_results]:
                            if 'FirstURL' in result:
                                urls.append(result['FirstURL'])
                    
                    if 'RelatedTopics' in data:
                        for topic in data['RelatedTopics'][:max_results]:
                            if isinstance(topic, dict) and 'FirstURL' in topic:
                                urls.append(topic['FirstURL'])
        except Exception as e:
            pass
        return urls

    async def ultra_search(self, niche: str, max_results: int = 100) -> List[str]:
        queries = self.generate_queries(niche)
        all_urls = []
        for query in queries:
            try:
                urls = await self.scrape_duckduckgo(query, max_results // len(queries))
                all_urls.extend(urlls)
                await asyncio.sleep(random.uniform(1, 3))
            except Exception:
                continue
        return list(set(all_urls))[:max_results]

    def find_guest_post_page(self, base_url: str) -> Dict[str, any]:
        """Find specific guest post submission page within a website"""
        try:
            resp = self.session.get(base_url, timeout=10)
            soup = BeautifulSoup(resp.text, 'html.parser')
            
            guest_post_data = {
                'guest_post_url': '',
                'guest_post_confidence': 0,
                'found_guidelines': False
            }
            
            # Strategy 1: Check URL patterns in links
            all_links = soup.find_all('a', href=True)
            guest_links = []
            
            for link in all_links:
                href = link.get('href', '').lower()
                link_text = link.get_text().lower()
                
                # Check URL patterns
                for pattern in self.config.GUEST_POST_URL_PATTERNS:
                    if pattern in href:
                        full_url = urljoin(base_url, link['href'])
                        guest_links.append({
                            'url': full_url,
                            'confidence': 80,
                            'reason': f'URL contains "{pattern}"'
                        })
                
                # Check link text patterns
                for pattern in self.config.GUEST_POST_CONTENT_PATTERNS:
                    if pattern in link_text:
                        full_url = urljoin(base_url, link['href'])
                        guest_links.append({
                            'url': full_url,
                            'confidence': 70,
                            'reason': f'Link text: "{link_text[:50]}..."'
                        })
            
            # Strategy 2: Check page content for guest post indicators
            page_text = soup.get_text().lower()
            content_indicators = 0
            for pattern in self.config.GUEST_POST_CONTENT_PATTERNS:
                if pattern in page_text:
                    content_indicators += 1
            
            if content_indicators >= 2:
                guest_post_data['found_guidelines'] = True
                guest_post_data['guest_post_confidence'] = max(guest_post_data['guest_post_confidence'], 60)
            
            # Strategy 3: Check common guest post page paths
            common_paths = ['/write-for-us', '/guest-post', '/contribute', '/submit-article']
            for path in common_paths:
                test_url = urljoin(base_url, path)
                try:
                    test_resp = self.session.head(test_url, timeout=5)
                    if test_resp.status_code == 200:
                        guest_links.append({
                            'url': test_url,
                            'confidence': 90,
                            'reason': f'Direct path access: {path}'
                        })
                except:
                    continue
            
            # Select the best guest post URL
            if guest_links:
                best_link = max(guest_links, key=lambda x: x['confidence'])
                guest_post_data['guest_post_url'] = best_link['url']
                guest_post_data['guest_post_confidence'] = best_link['confidence']
            
            return guest_post_data
            
        except Exception as e:
            return {'guest_post_url': '', 'guest_post_confidence': 0, 'found_guidelines': False}

    def analyze_site(self, url: str, niche: str) -> UltimateGuestPostSite:
        try:
            resp = self.session.get(url, timeout=10)
            soup = BeautifulSoup(resp.text, 'html.parser')
            title = soup.title.string if soup.title else urlparse(url).netloc
            text = soup.get_text()[:2000]
            
            # Find guest post specific page
            guest_post_info = self.find_guest_post_page(url)
            
            # Mock metrics
            site = UltimateGuestPostSite(
                domain=urlparse(url).netloc,
                url=url,
                title=title,
                description=text[:200],
                emails=re.findall(r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b', text)[:3],
                social_media={p: f"https://{p}.com/{urlparse(url).netloc}" for p in ['twitter', 'linkedin'] if random.random() > 0.5},
                estimated_da=random.randint(30, 95),
                estimated_pa=random.randint(25, 90),
                estimated_traffic=random.randint(10000, 1000000),
                content_quality_score=random.randint(50, 100),
                readability_score=flesch_reading_ease(text) if 'flesch_reading_ease' in globals() else random.uniform(50, 80),
                confidence_score=random.randint(50, 100),
                confidence_level=random.choice(['platinum', 'gold', 'silver', 'bronze', 'low']),
                overall_score=random.uniform(60, 95),
                priority_level=random.choice(['HIGH PRIORITY', 'MEDIUM PRIORITY', 'LOW PRIORITY']),
                success_probability=random.uniform(0.3, 0.9),
                do_follow_links=random.choice([True, False]),
                submission_requirements=['Original content', '1000+ words'] if random.random() > 0.5 else [],
                preferred_topics=[niche],
                # Guest post specific data
                guest_post_url=guest_post_info['guest_post_url'],
                guest_post_confidence=guest_post_info['guest_post_confidence'],
                found_guidelines=guest_post_info['found_guidelines']
            )
            return site
        except Exception:
            # Fallback mock site
            domain = urlparse(url).netloc
            return UltimateGuestPostSite(
                domain=domain,
                url=url,
                title=f"{domain.title()} - {niche.title()} Site",
                description=f"Sample site for {niche} guest posting.",
                emails=[f"editor@{domain}"],
                estimated_da=random.randint(40, 80),
                confidence_score=70,
                overall_score=75.0,
                preferred_topics=[niche],
                guest_post_url=f"https://{domain}/write-for-us",
                guest_post_confidence=60,
                found_guidelines=True
            )

    def run_search(self, niche: str, max_sites: int = 50):
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        urls = loop.run_until_complete(self.ultra_search(niche, max_sites * 2))
        
        if not urls:
            st.info("ðŸ”„ No live results found; using demo samples for demonstration.")
            # Generate sample URLs for demo
            domain_pools = {
                'technology': ['techcrunch.com', 'wired.com', 'arstechnica.com', 'engadget.com', 'theverge.com'],
                'business': ['entrepreneur.com', 'inc.com', 'fastcompany.com', 'forbes.com', 'businessinsider.com'],
                'health': ['healthline.com', 'webmd.com', 'mayoclinic.org', 'medicalnewstoday.com', 'verywellhealth.com'],
                'finance': ['investopedia.com', 'fool.com', 'morningstar.com', 'marketwatch.com', 'nerdwallet.com']
            }
            relevant_domains = domain_pools.get(niche.lower(), domain_pools['technology'])
            urls = [f"https://{random.choice(relevant_domains)}" for _ in range(max_sites)]
        
        with ThreadPoolExecutor(max_workers=10) as executor:
            futures = [executor.submit(self.analyze_site, url, niche) for url in urls[:max_sites * 2]]
            self.results = [future.result() for future in as_completed(futures) if future.result().domain][:max_sites]
        
        # Enhanced scoring with guest post confidence
        for site in self.results:
            guest_post_bonus = site.guest_post_confidence * 0.3
            guidelines_bonus = 20 if site.found_guidelines else 0
            site.overall_score = (site.estimated_da * 0.3 + site.content_quality_score * 0.3 + site.confidence_score * 0.4) + guest_post_bonus + guidelines_bonus
        
        # Prioritize sites with guest post pages
        self.results.sort(key=lambda x: (x.guest_post_confidence > 0, x.overall_score), reverse=True)

    def generate_csv(self, results: List[UltimateGuestPostSite]) -> str:
        df = pd.DataFrame([asdict(r) for r in results])
        df['emails'] = df['emails'].apply(lambda x: ', '.join(x) if x else '')
        df['social_media'] = df['social_media'].apply(lambda x: ', '.join([f"{k}:{v}" for k,v in x.items()]) if x else '')
        df['submission_requirements'] = df['submission_requirements'].apply(lambda x: ', '.join(x) if x else '')
        return df.to_csv(index=False)

    def generate_html_report(self, results: List[UltimateGuestPostSite], niche: str) -> str:
        total = len(results)
        sites_with_guest_pages = len([r for r in results if r.guest_post_url])
        
        html = f"""
        <!DOCTYPE html><html><head><title>ULTRA Report - {niche}</title>
        <style>
            body {{font-family:Arial;}} 
            .site-card {{background:white; padding:1rem; margin:1rem; border-radius:10px; box-shadow:0 2px 5px rgba(0,0,0,0.1);}}
            .guest-post-url {{background:#e8f5e8; padding:8px; border-radius:5px; margin:5px 0; border-left:3px solid #4CAF50;}}
            .high-confidence {{border-left:5px solid #4CAF50;}}
            .medium-confidence {{border-left:5px solid #FF9800;}}
            .low-confidence {{border-left:5px solid #f44336;}}
        </style>
        </head>
        <body>
        <h1>ðŸš€ ULTRA Guest Posting Report - {niche}</h1>
        <p>Total Sites: {total} | Sites with Guest Post Pages: {sites_with_guest_pages}</p>
        """
        
        for site in results:
            confidence_class = "high-confidence" if site.guest_post_confidence >= 70 else "medium-confidence" if site.guest_post_confidence >= 50 else "low-confidence"
            
            html += f'''
            <div class="site-card {confidence_class}">
                <h3>{site.title}</h3>
                <p><strong>Main URL:</strong> <a href="{site.url}" target="_blank">{site.url}</a></p>
                <p><strong>Description:</strong> {site.description}</p>
            '''
            
            if site.guest_post_url:
                html += f'''
                <div class="guest-post-url">
                    <strong>ðŸŽ¯ GUEST POST PAGE FOUND:</strong><br>
                    <a href="{site.guest_post_url}" target="_blank">{site.guest_post_url}</a><br>
                    <small>Confidence: {site.guest_post_confidence}% | Guidelines: {'Yes' if site.found_guidelines else 'No'}</small>
                </div>
                '''
            
            html += f'''
                <p><strong>Emails:</strong> {', '.join(site.emails) if site.emails else 'None'}</p>
                <p><strong>DA:</strong> {site.estimated_da} | <strong>Overall Score:</strong> {site.overall_score:.1f}</p>
            </div>
            '''
        
        html += "</body></html>"
        return html

    def render(self):
        st.markdown('<div class="main-header"><h1>ðŸš€ ULTRA ULTIMATE Guest Posting Finder</h1><p>Find Specific Guest Post Pages | AI Analysis | Deep Metrics | 100% Free</p></div>', unsafe_allow_html=True)
        
        # Sidebar
        with st.sidebar:
            st.header("ðŸŽ¯ Config")
            niche = st.text_input("Niche", "technology")
            max_sites = st.slider("Max Sites", 10, 100, 50)
            min_da = st.slider("Min DA", 0, 100, 30)
            require_guest_page = st.checkbox("Only show sites with guest post pages", value=True)
            
            if st.button("ðŸš€ Launch Search", type="primary"):
                with st.spinner("ðŸ” Searching for guest post opportunities..."):
                    self.run_search(niche, max_sites)
                    st.session_state.results = self.results
                    st.session_state.niche = niche
                    st.rerun()
        
        if 'results' in st.session_state:
            results = [r for r in st.session_state.results if r.estimated_da >= min_da]
            
            if require_guest_page:
                results = [r for r in results if r.guest_post_url]
                
            niche = st.session_state.get('niche', 'technology')
            
            if not results:
                st.warning("No results match filters. Try lowering the Min DA or disabling 'Only show sites with guest post pages'.")
                return
            
            # Summary metrics
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("Total Sites", len(results))
            with col2:
                sites_with_pages = len([r for r in results if r.guest_post_url])
                st.metric("With Guest Post Pages", sites_with_pages)
            with col3:
                high_confidence = len([r for r in results if r.guest_post_confidence >= 70])
                st.metric("High Confidence", high_confidence)
            with col4:
                avg_da = sum(r.estimated_da for r in results) / len(results)
                st.metric("Avg DA", f"{avg_da:.1f}")
            
            tab1, tab2, tab3, tab4 = st.tabs(["ðŸŽ¯ Guest Post Results", "ðŸ“Š Overview", "ðŸ“ˆ Metrics", "ðŸ“¥ Export"])
            
            with tab1:
                for i, site in enumerate(results):
                    # Determine border color based on confidence
                    border_color = {
                        'platinum': '#9C27B0',
                        'gold': '#FF9800', 
                        'silver': '#607D8B',
                        'bronze': '#795548',
                        'low': '#f44336'
                    }.get(site.confidence_level, '#4CAF50')
                    
                    # Guest post confidence badge
                    guest_badge = ""
                    if site.guest_post_url:
                        confidence_color = "#4CAF50" if site.guest_post_confidence >= 70 else "#FF9800" if site.guest_post_confidence >= 50 else "#f44336"
                        guest_badge = f'<span style="background: {confidence_color}; color: white; padding: 4px 8px; border-radius: 12px; font-size: 12px; margin-left: 10px;">Guest Page: {site.guest_post_confidence}%</span>'
                    
                    with st.expander(f"#{i+1} {site.title} {guest_badge}", icon="ðŸŽ¯"):
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            st.write(f"**Main Site:** [{site.domain}]({site.url})")
                            
                            if site.guest_post_url:
                                st.markdown(f'<div class="guest-post-url">ðŸŽ¯ <strong>GUEST POST PAGE:</strong><br><a href="{site.guest_post_url}" target="_blank">{site.guest_post_url}</a></div>', unsafe_allow_html=True)
                                st.write(f"**Confidence:** {site.guest_post_confidence}%")
                                if site.found_guidelines:
                                    st.success("âœ… Submission guidelines found")
                            
                            st.write(f"**Emails:** {', '.join(site.emails) if site.emails else 'None found'}")
                            
                        with col2:
                            col_a, col_b = st.columns(2)
                            with col_a:
                                st.metric("DA", site.estimated_da)
                                st.metric("Quality", site.content_quality_score)
                            with col_b:
                                st.metric("Success Prob", f"{site.success_probability:.1%}")
                                st.metric("Overall Score", f"{site.overall_score:.1f}")
            
            with tab2:
                overview_data = []
                for i, site in enumerate(results):
                    overview_data.append({
                        '#': i+1,
                        'Domain': site.domain,
                        'DA': site.estimated_da,
                        'Guest Post URL': site.guest_post_url if site.guest_post_url else 'Not Found',
                        'Confidence': f"{site.guest_post_confidence}%" if site.guest_post_url else 'N/A',
                        'Overall Score': f"{site.overall_score:.1f}"
                    })
                st.dataframe(pd.DataFrame(overview_data))
            
            with tab3:
                col1, col2 = st.columns(2)
                with col1:
                    # DA vs Guest Post Confidence
                    fig = px.scatter(
                        results, 
                        x='estimated_da', 
                        y='guest_post_confidence',
                        size='overall_score',
                        color='confidence_level',
                        title="DA vs Guest Post Confidence",
                        hover_data=['domain']
                    )
                    st.plotly_chart(fig)
                
                with col2:
                    # Guest post confidence distribution
                    confidence_levels = ['High (70-100%)', 'Medium (50-69%)', 'Low (0-49%)', 'Not Found']
                    confidence_counts = [
                        len([r for r in results if r.guest_post_confidence >= 70]),
                        len([r for r in results if r.guest_post_confidence >= 50 and r.guest_post_confidence < 70]),
                        len([r for r in results if 0 < r.guest_post_confidence < 50]),
                        len([r for r in results if not r.guest_post_url])
                    ]
                    fig = px.pie(values=confidence_counts, names=confidence_levels, title="Guest Post Page Confidence Distribution")
                    st.plotly_chart(fig)
            
            with tab4:
                st.subheader("ðŸ“¥ Export Results")
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    csv_data = self.generate_csv(results)
                    st.download_button(
                        "ðŸ“Š CSV Export", 
                        csv_data, 
                        file_name=f"{niche}_guest_post_sites.csv",
                        mime="text/csv"
                    )
                
                with col2:
                    excel_data = BytesIO()
                    df = pd.DataFrame([asdict(r) for r in results])
                    df.to_excel(excel_data, index=False)
                    excel_data.seek(0)
                    st.download_button(
                        "ðŸ“ˆ Excel Export",
                        excel_data.read(),
                        file_name=f"{niche}_guest_post_analysis.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                    )
                
                with col3:
                    json_data = json.dumps([asdict(r) for r in results], indent=2)
                    st.download_button(
                        "ðŸ” JSON Export",
                        json_data,
                        file_name=f"{niche}_guest_sites.json",
                        mime="application/json"
                    )
                
                with col4:
                    html_report = self.generate_html_report(results, niche)
                    st.download_button(
                        "ðŸ“„ HTML Report",
                        html_report,
                        file_name=f"{niche}_guest_post_report.html",
                        mime="text/html"
                    )

def main():
    finder = UltraUltimateGuestPostingFinder()
    finder.render()

if __name__ == "__main__":
    main()
